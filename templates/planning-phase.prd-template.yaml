# Planning Phase PRD Template
# Purpose: Generate validated Ralphy YAML inputs for creating implementation plans
# This template follows research-backed best practices from docs/best-practices.md

metadata:
  template_version: "1.0.1"
  template_purpose: "Generate Ralphy YAML inputs for implementation planning"
  generated_by: "planning-phase-prd-template"
  generator_version: "opencode-1.0"
  generated_at: "{{timestamp}}"
  quality_target: 0.95  # Minimum quality score for approval

global_constraints:
  # Research-backed constraints from docs/best-practices.md
  style_anchors_required: 2-3  # Per task, critical for preventing drift
  task_sizing_minutes: 30-150  # Optimal task duration range
  affirmative_constraints: true  # Use "do this" not "don't do that"
  context_positioning: "critical-specs-at-edges"  # Avoid "lost in middle" problem

  forbidden_patterns:
    - pattern: "\\bany\\b"
      message: "Use unknown with type guards instead"
    - pattern: "@ts-ignore"
      message: "Fix type errors properly"
    - pattern: "eslint-disable"
      message: "Address lint issues instead of disabling"

  required_patterns:
    - pattern: "import.*zod"
      when: "implementation_phase"
    - pattern: "export const.*Schema = z\\.object"
      when: "implementation_phase"
    - pattern: "export type.* = z\\.infer"
      when: "implementation_phase"

# Tasks
tasks:
  # Phase 1: Requirements Analysis
  - id: "planning-001"
    title: "Analyze requirements and extract key components"
    description: "Read the provided requirements document and extract:\n1. Core functional requirements\n2. Non-functional requirements (performance, security, etc.)\n3. Integration points with existing systems\n4. Dependencies and constraints\n5. Acceptance criteria\n\nOutput a structured analysis that will inform task breakdown."

    outputs:
      structured_analysis: "structured_analysis.json"
    files_in_scope:
      - "{{requirements_file}}"  # Placeholder for actual requirements file
    style_anchors:
      - file: "{{style_anchor_problem_statement}}"
        reason: "Example of origin and problem framing (replace with project-specific anchor)"
      - file: "{{style_anchor_requirements_example}}"
        reason: "Additional example anchor for requirements analysis (replace with project-specific anchor)"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "All requirements categories identified"
        - "No ambiguous requirements left unaddressed"
    output_format: "structured_analysis.json"
    estimated_duration_minutes: 45

  # Phase 2: Codebase Pattern Discovery (from knowledge base)
  - id: "planning-002"
    title: "Retrieve relevant patterns from knowledge base"
    description: "Query the knowledge base for:\n1. Existing style anchors relevant to requirements\n2. Coding standards and patterns for similar tasks\n3. Previous successful task implementations\n4. Common pitfalls to avoid\n\nUse semantic search to find the most relevant patterns."

    depends_on: ["planning-001"]
    outputs:
      patterns_report: "patterns_report.json"
    files_in_scope:
      - "{{knowledge_db_path}}"  # Path to knowledge DB (default: .prompt-stack/knowledge.db)
      - note: "If the knowledge DB is not present, set {{knowledge_db_path}} to a valid path or run 'prompt-stack init' to create one."
      - "docs/best-practices.md"   # Research-backed practices
      - "docs/ralphy-inputs.schema.json"
    style_anchors:
      - file: "{{style_anchor_jit_caching}}"
        reason: "JIT caching & pattern discovery examples (replace with project-specific anchor)"
      - file: "{{style_anchor_pattern_examples}}"
        reason: "Pattern examples for similar tasks (replace with project-specific anchor)"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "At least 5 relevant patterns identified"
        - "Style anchors categorized by relevance"
        - "Confidence scores > 0.7 for selected patterns"
    output_format: "patterns_report.json"
    estimated_duration_minutes: 45

  # Phase 3: Task Breakdown and Sizing
  - id: "planning-003"
    title: "Break down requirements into optimally sized tasks"
    description: "Based on requirements analysis and patterns:\n1. Create task breakdown following single responsibility principle\n2. Size each task to 30-150 minute range\n3. Identify dependencies between tasks\n4. Assign appropriate style anchors (2-3 per task)\n5. Estimate context tokens per task\n\nApply research-backed task sizing principles."

    depends_on: ["planning-001", "planning-002"]
    outputs:
      task_breakdown: "task_breakdown.yaml"
    files_in_scope:
      - "{{outputs.planning-001.structured_analysis}}"  # From planning-001
      - "{{outputs.planning-002.patterns_report}}"      # From planning-002
    style_anchors:
      - file: "docs/task-sizing.md"
        reason: "Research basis for task sizing"
      - file: "docs/best-practices.md:171-176"
        reason: "Task sizing research section"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "All tasks sized 30-150 minutes"
        - "Each task has clear single responsibility"
        - "Dependency graph is acyclic"
        - "Style anchors assigned (2-3 per task)"
    output_format: "task_breakdown.yaml"
    estimated_duration_minutes: 60

  # Phase 4: Generate Ralphy YAML Inputs
  - id: "planning-004"
    title: "Generate complete Ralphy YAML inputs"
    description: "Create the final Ralphy YAML inputs file that includes:\n1. Project metadata (name, description, version)\n2. Global constraints and standards\n3. Task definitions with style anchors\n4. Verification steps (pre-commit, post-commit)\n5. Context optimization specifications\n6. Model preferences and strategies\n\nFollow the structure defined in docs/ralphy-inputs.md and ensure produced outputs are declared in 'outputs' for downstream tasks."

    depends_on: ["planning-003"]
    outputs:
      implementation_plan: "implementation-plan.yaml"
    files_in_scope:
      - "{{outputs.planning-003.task_breakdown}}"  # From planning-003
      - "docs/ralphy-inputs.md"      # Input specification
      - "docs/best-practices.md"     # Research validation
      - "docs/ralphy-inputs.schema.json"
    style_anchors:
      - file: "docs/ralphy-inputs.md:43-88"  # Example minimal Ralphy inputs
        reason: "Reference structure for YAML inputs"
      - file: "docs/ralphy-yaml-spec.md"
        reason: "Ralphy YAML spec examples"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    required_patterns:
      - "name: "
      - "description: "
      - "version: "
      - "tasks:"
      - "style_anchors:"
      - "verification:"
    verification:
      pre_commit:
        - "YAML structure matches docs/ralphy-inputs.md"
        - "All required fields present"
        - "Style anchors (2-3) per task"
        - "Affirmative constraints used"
    output_format: "implementation-plan.yaml"
    estimated_duration_minutes: 45

  # Phase 4a: YAML syntax validation (new)
  # Validator integration: Prefer built-in validator at `prompt-stack validate` (internal/validation).
  # The planning pipeline should call `prompt-stack validate` to produce structured JSON reports and the final_quality_report.json used in downstream steps.

  - id: "planning-004a"
    title: "Validate YAML syntax using validator tool"
    description: "Run the YAML validator tool to ensure the generated Ralphy inputs have valid YAML syntax and structure. This validates basic YAML correctness before schema validation."

    depends_on: ["planning-004"]
    outputs:
      yaml_validation: "yaml_validation_report.json"
    files_in_scope:
      - "{{outputs.planning-004.implementation_plan}}"
      - "tools/validate_yaml.go"
      - "docs/ralphy-yaml-spec.md"
    style_anchors:
      - file: "tools/validate_yaml.go"
        reason: "YAML validator tool implementation"
      - file: "docs/ralphy-yaml-spec.md"
        reason: "Yaml spec examples for validation rules"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "YAML syntax validation passes using tools/validate_yaml.go"
        - "No YAML parsing errors or structural issues"
    output_format: "yaml_validation_report.json"
    estimated_duration_minutes: 20

  # Phase 4b: Schema validation (new)
  - id: "planning-004b"
    title: "Validate generated Ralphy YAML against JSON Schema"
    description: "Run JSON Schema validation of the generated Ralphy inputs against docs/ralphy-inputs.schema.json. Fail on schema errors and include detailed diagnostics."

    depends_on: ["planning-004a"]
    outputs:
      schema_validation: "schema_validation_report.json"
    files_in_scope:
      - "{{outputs.planning-004.implementation_plan}}"
      - "docs/ralphy-inputs.schema.json"
      - "docs/ralphy-yaml-spec.md"
    style_anchors:
      - file: "docs/ralphy-inputs.schema.json"
        reason: "JSON Schema reference for Ralphy inputs"
      - file: "docs/ralphy-yaml-spec.md"
        reason: "Yaml spec examples for validation rules"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "JSON Schema validation passes against docs/ralphy-inputs.schema.json"
    output_format: "schema_validation_report.json"
    estimated_duration_minutes: 30

  # Phase 4c: Secrets and sensitive-data scan (new)
  - id: "planning-004c"
    title: "Scan generated YAML for embedded secrets"
    description: "Ensure no API keys, tokens, or secrets are present in the generated YAML. If secrets are required, confirm they are referenced via secure vault/env and not in the file."

    depends_on: ["planning-004b"]
    outputs:
      secrets_scan: "secrets_scan_report.json"
    files_in_scope:
      - "{{outputs.planning-004.implementation_plan}}"
      - "docs/requirements/main.md"
    verification:
      pre_commit:
        - "Zero embedded secrets found (api_key, secret, AWS, private_key patterns)"
        - "Any required secrets are referenced via vault or env placeholders"
    output_format: "secrets_scan_report.json"
    estimated_duration_minutes: 30

  # Phase 5: AI Validation - Style Anchors Compliance
  - id: "planning-005"
    title: "Validate style anchors compliance"
    description: "Review the generated Ralphy YAML to ensure:\n1. Each task has 2-3 style anchors\n2. Style anchors are relevant to task type\n3. Anchor files exist in the codebase\n4. Anchor reasons are specific and helpful\n\nThis is critical for preventing architectural drift."

    depends_on: ["planning-004"]
    outputs:
      anchors_validation: "validation_report_anchors.json"
    files_in_scope:
      - "{{outputs.planning-004.implementation_plan}}"
      - "docs/best-practices.md:164-170"  # Style anchors research section
    style_anchors:
      - file: "{{style_anchor_research_report}}"
        reason: "Research basis for anchor importance (replace with project-specific anchor)"
      - file: "{{style_anchor_best_practices}}"
        reason: "Best-practices excerpt (replace with project-specific anchor)"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "All tasks have 2-3 style anchors"
        - "Anchor relevance score > 0.8"
        - "Anchor files exist and are accessible"
        - "Anchor reasons are specific (not generic)"
    output_format: "validation_report_anchors.json"
    estimated_duration_minutes: 30

  # Phase 6: AI Validation - Task Sizing Compliance
  - id: "planning-006"
    title: "Validate task sizing compliance"
    description: "Review task sizing to ensure:\n1. All tasks are 30-150 minutes\n2. No task is too large (risk of context overflow)\n3. No task is too small (inefficient overhead)\n4. Task dependencies are properly sequenced\n\nFlag any tasks that need splitting or merging."

    depends_on: ["planning-004"]
    outputs:
      sizing_validation: "validation_report_sizing.json"
    files_in_scope:
      - "{{outputs.planning-004.implementation_plan}}"
      - "docs/task-sizing.md"  # Task sizing heuristics
    style_anchors:
      - file: "docs/task-sizing.md"
        reason: "Example of optimal task sizing validation"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "All tasks within 30-150 minute range"
        - "No task exceeds max_files limit"
        - "Dependency graph is optimal"
        - "Parallel execution opportunities identified"
    output_format: "validation_report_sizing.json"
    estimated_duration_minutes: 30

  # Phase 7: AI Validation - Affirmative Constraints
  - id: "planning-007"
    title: "Validate affirmative constraints usage"
    description: "Review constraints to ensure:\n1. All constraints use affirmative language (\"do this\")\n2. No negative phrasing (\"don't do that\")\n3. Constraints are specific and actionable\n4. Constraints reference existing patterns when possible\n\nResearch shows 40%+ better compliance with affirmative framing."

    depends_on: ["planning-004"]
    outputs:
      constraints_validation: "validation_report_constraints.json"
    files_in_scope:
      - "{{outputs.planning-004.implementation_plan}}"
      - "docs/best-practices.md:178-183"  # Affirmative constraints research
    style_anchors:
      - file: "docs/best-practices.md"
        reason: "Constraint patterns reference best-practices guidance"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "Zero instances of negative phrasing"
        - "All constraints are affirmative"
        - "Constraints reference existing patterns"
        - "Constraints are specific and testable"
    output_format: "validation_report_constraints.json"
    estimated_duration_minutes: 10

  # Phase 8: AI Validation - Implementation Guidelines Compliance (planning only — no tests generated)
  - id: "planning-008"
    title: "Validate implementation guidelines inclusion"
    description: |
      Review the generated plan to ensure implementation-phase guidelines are present where applicable. Specifically:
      1. Identify tasks that will require test-first workflows at implementation time
      2. Ensure task descriptions include 'testable' acceptance criteria when appropriate
      3. Reference implementation guidance and style anchors for the implementation team

      Note: This planning-phase template does NOT generate tests or TDD artifacts; it only records guidance for later implementation phases.

    depends_on: ["planning-004"]
    outputs:
      implementation_guidelines_validation: "validation_report_implementation_guidelines.json"
    files_in_scope:
      - "{{outputs.planning-004.implementation_plan}}"
      - "docs/best-practices.md"  # Implementation guidance reference
    style_anchors:
      - file: "docs/best-practices.md"
        reason: "Best-practices excerpt as implementation guideline reference"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "Implementation guidelines identified for tasks that will need tests during implementation"
        - "Testable acceptance criteria referenced where appropriate"
        - "No tests are generated in the planning phase"
    output_format: "validation_report_implementation_guidelines.json"
    estimated_duration_minutes: 30

  # Phase 9: AI Validation - Multi-Layer Enforcement
  - id: "planning-009"
    title: "Validate multi-layer enforcement and commit/scope policies"
    description: "Review verification layers to ensure:\n1. Prompt-level constraints in YAML\n2. IDE/LSP integration considerations\n3. Pre-commit hook specifications\n4. CI check definitions\n5. Runtime validation where applicable\n6. Commit/revert and file-scope enforcement (atomic commits, files_in_scope enforcement)\n\nMulti-layer enforcement is critical for preventing drift. Reference docs/opencode-rules.md and docs/requirements/main.md for commit policy."

    depends_on: ["planning-004"]
    outputs:
      enforcement_validation: "validation_report_enforcement.json"
    files_in_scope:
      - "{{outputs.planning-004.implementation_plan}}"
      - "docs/best-practices.md:184-193"  # Multi-layer enforcement research
      - "docs/opencode-rules.md"
      - "docs/requirements/main.md"
      - "docs/drift-policy.md"
    style_anchors:
      - file: "docs/opencode-rules.md"
        reason: "Project-level rules & constraints"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "At least 3 verification layers specified"
        - "Pre-commit hooks defined"
        - "CI checks included"
        - "Runtime validation for critical paths"
        - "Files_in_scope present for all tasks"
        - "Commit-per-task behavior documented or flag set"
        - "Scope enforcement rules present (flag drift detection)"
    output_format: "validation_report_enforcement.json"
    estimated_duration_minutes: 30

  # Phase 10: Generate Final Quality Report
  - id: "planning-010"
    title: "Generate comprehensive quality report"
    description: "Aggregate all validation results and generate:\n1. Overall quality score (0.0-1.0)\n2. Detailed issue breakdown\n3. Recommendations for improvement\n4. Approval status (APPROVED/REJECTED/NEEDS_REVISION)\n\nQuality score must be ≥0.95 for approval."

    depends_on: [
      "planning-005",
      "planning-006",
      "planning-007",
      "planning-008",
      "planning-009",
      "planning-004a",
      "planning-004b",
      "planning-004c"
    ]
    outputs:
      final_quality_report: "final_quality_report.json"
    files_in_scope:
      - "{{outputs.planning-005.anchors_validation}}"
      - "{{outputs.planning-006.sizing_validation}}"
      - "{{outputs.planning-007.constraints_validation}}"
      - "{{outputs.planning-008.implementation_guidelines_validation}}"
      - "{{outputs.planning-009.enforcement_validation}}"
      - "{{outputs.planning-004a.yaml_validation}}"
      - "{{outputs.planning-004b.schema_validation}}"
      - "{{outputs.planning-004c.secrets_scan}}"
    style_anchors:
      - file: "docs/best-practices.md"
        reason: "Example of comprehensive quality reporting"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "All validation reports aggregated"
        - "Quality score calculated (0.0-1.0)"
        - "Issue categorization complete"
        - "Clear recommendations provided"
    output_format: "final_quality_report.json"
    estimated_duration_minutes: 20

  # Phase 11: Apply Fixes and Generate Final YAML
  - id: "planning-011"
    title: "Apply fixes and generate final Ralphy YAML"
    description: "Based on quality report recommendations:\n1. Apply automatic fixes where possible\n2. Flag issues requiring manual intervention\n3. Regenerate Ralphy YAML with improvements\n4. Create final version with quality score metadata\n\nOnly proceed if quality score ≥0.95."

    depends_on: ["planning-010"]
    outputs:
      final_implementation_plan: "final-implementation-plan.yaml"
    files_in_scope:
      - "{{outputs.planning-004.implementation_plan}}"  # Initial version
      - "{{outputs.planning-010.final_quality_report}}"
    style_anchors:
      - file: "docs/best-practices.md"
        reason: "Example of final YAML generation with fixes"
      - file: "examples/style-anchor/pkg/greeter/greeter.go"
        reason: "Repository example with code + tests + README (high-leverage anchor)"
    verification:
      pre_commit:
        - "Quality score ≥0.95"
        - "Critical issues resolved"
        - "All warnings addressed or justified"
        - "Final YAML passes all validations (yaml syntax, schema, secrets, constraints)"
    output_format: "final-implementation-plan.yaml"
    estimated_duration_minutes: 25
    completion_signal: "<promise>PLANNING_COMPLETE</promise>"

# Template Usage Instructions
instructions: |
  This template generates validated Ralphy YAML inputs for implementation planning.

  Usage:
  1. Replace {{placeholders}} with actual values or provide equivalent runtime mappings:
      - {{requirements_file}}: Path to requirements document (required). You may pass this mapping at runtime or replace the placeholder with an explicit path.

   2. Output placeholder mapping (the template publishes named outputs for each task):
      - planning-001 outputs.structured_analysis => {{outputs.planning-001.structured_analysis}} (structured_analysis.json)
      - planning-002 outputs.patterns_report => {{outputs.planning-002.patterns_report}} (patterns_report.json)
      - planning-003 outputs.task_breakdown => {{outputs.planning-003.task_breakdown}} (task_breakdown.yaml)
      - planning-004 outputs.implementation_plan => {{outputs.planning-004.implementation_plan}} (implementation-plan.yaml)
      - planning-004a outputs.yaml_validation => {{outputs.planning-004a.yaml_validation}}
      - planning-004b outputs.schema_validation => {{outputs.planning-004b.schema_validation}}
      - planning-004c outputs.secrets_scan => {{outputs.planning-004c.secrets_scan}}
      - planning-005..planning-011 outputs are similarly named and used by downstream tasks

  3. Required pre-conditions:
     - Knowledge base ({{knowledge_db_path}}) should be populated for best results
     - If using the template as a style anchor, replace any {{style_anchor_*}} placeholders with project-specific file paths or supply a mapping at runtime.
      - docs/best-practices.md, docs/ralphy-inputs.schema.json, docs/ralphy-yaml-spec.md, docs/task-sizing.md, docs/drift-policy.md, docs/opencode-rules.md must be available in repo
      - Repository examples like `examples/style-anchor/pkg/greeter/greeter.go` are high-leverage anchors; include tests and README for TDD/context

  4. Execution flow:
     - Run tasks sequentially according to dependencies
     - Each task validates its output before proceeding
     - Final output: final-implementation-plan.yaml (quality ≥0.95)

  5. Quality gates:
  - Style anchors: 2-3 per task (critical)
  - Task sizing: 30-150 minutes (optimal)
  - Affirmative constraints: 100% compliance
  - TDD workflow: Where applicable
  - Multi-layer enforcement: ≥3 layers
  - No embedded secrets in final YAML
  - Final YAML MUST pass YAML syntax validation using `prompt-stack validate` (internal/validation)
  - Final YAML MUST pass JSON Schema validation in docs/ralphy-inputs.schema.json (validator will perform this check)


  6. Output artifacts:
  - final-implementation-plan.yaml: Ready for execution
  - final_quality_report.json: Detailed validation results (produced by `prompt-stack validate` via internal/validation)
  - Intermediate analysis and validation reports


# Research Compliance Summary
research_compliance:
  style_anchors: "CRITICAL - 40%+ quality improvement"
  task_sizing: "CRITICAL - Prevents context overflow"
  affirmative_constraints: "HIGH - 40%+ better compliance"
  # Note: TDD integration is part of implementation; this planning-phase template does not require creating tests. If you want to include TDD checks in later phases, add appropriate tasks in the implementation template.
  multi_layer_enforcement: "CRITICAL - Prompt-level rules insufficient"
  context_positioning: "MEDIUM - Avoid 'lost in middle' problem"
  self_consistency: "MEDIUM - 30%+ error reduction"
  model_specific_strategies: "LOW - Implementation detail"

# Expected Performance
performance_targets:
  total_duration_minutes: 190  # Sum of all task estimates (approx)
  parallel_opportunities: "Limited (sequential analysis)"
  context_reduction_target: "80%+ vs naive approach"
  quality_score_target: ">=0.95"
  first_pass_success_target: ">=90%"
